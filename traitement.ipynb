{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ea988a",
   "metadata": {},
   "source": [
    "# Projet data management : Morbidité hospitalière aux cours des années 2018 - 2022 \n",
    "\n",
    "Ce projet de Data Management à pour but de filtrer, de traiter et de représenter des données provenant d'une base de la morbidité hospitalière durant les années comprises entre 2018 et 2022. Ce premier tableau représente le taux de recours aux établissements de soins de courte durée (MCO) selon le sexe, l’âge des patients et la pathologie traitée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05dc22b",
   "metadata": {},
   "source": [
    "## Importation des données\n",
    "\n",
    "Dans cette première partie, nous allons importer la dase et la représenter sous forme de tableau avec DataFrame. Il est importer de connaître la base de données et donc utiliser des outils de Pandas pour l'intéroger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des outils\n",
    "import pandas as pd         # permettant la création de fataframe\n",
    "import json                 # pour lire les jason\n",
    "import plotly.express as px # pour ploter des figures\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture du csv\n",
    "df = pd.read_csv('tableau_1.csv', sep = ';')\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On controle la dimension du tableau de données\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on affiche les informations du tableau\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fa06c",
   "metadata": {},
   "source": [
    "## Filtrage\n",
    "\n",
    "Dans cette seconde partie nous allons filtrer la base de données, modifier le type object du nbr recours en int afin de pouvoir faire des opérations et traiter les valeurs non disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6608dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette base de données fait un rassemblement départemental, régional et national. Nous allons les séparer les uns des autres\n",
    "df_dep = df[df['Niveau']=='Départements']\n",
    "df_reg = df[df['Niveau']=='Régions']\n",
    "df_fr = df[df['Niveau']== 'France']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e93316",
   "metadata": {},
   "source": [
    "Nous allons étudier le taux de recours aux établissements de soin par département. Donc uniquement utiliser le data frame `df_sejour`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c30e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38322ad4",
   "metadata": {},
   "source": [
    "Ici le titre ``ind_freq`` n'est pas très explicite. Cette valeur représente le nombre  de recours aux établissements de santé par département. Nous allons la renomer ``Taux recours``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba59303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dep = df_dep.rename(columns={\"ind_freq\": \"nbr recours\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire les Dom Tom afin de simplifier la representation cartographique (voir plus loin)\n",
    "# on retire aussi la somme des recours pour toutes pathologies \"TOTAL TOUTES CAUSES\"\n",
    "df_filt_DT_path = df_dep[~df_dep.PATHOLOGIE.str.contains('TOTAL') \n",
    "                       & ~df_dep.ZONE.str.contains('971')\n",
    "                       & ~df_dep.ZONE.str.contains('972')\n",
    "                       & ~df_dep.ZONE.str.contains('973')\n",
    "                       & ~df_dep.ZONE.str.contains('974')\n",
    "                       & ~df_dep.ZONE.str.contains('976')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On souhaiterai faire une différentiation des sexes, on ne conserve donc pas les ensemble \"sexe\"\n",
    "# on souhaite garder un dataframe rassemblant les ages mais qui différencie les sexe\n",
    "df_tot_age = df_filt_DT_path[~df_filt_DT_path['SEXE'].str.contains('Ensemble') & \n",
    "                                df_filt_DT_path['Tranche d\\'age'].str.contains('Tous âges confondus') ]\n",
    "df_tot_age = df_tot_age.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299af797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puis un second DataFramme avec le nbr recours par tranche d'âge\n",
    "df_tranch_age = df_filt_DT_path[df_filt_DT_path['SEXE'].str.contains('Ensemble') & \n",
    "                                ~df_filt_DT_path['Tranche d\\'age'].str.contains('Tous âges confondus') ]\n",
    "df_tranch_age = df_tranch_age.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6faaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eaf278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tranch_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58822519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous faisons un convertion de l'objet nbr recours en int.\n",
    "df_tot_age['nbr recours'], df_tranch_age['nbr recours']  = pd.to_numeric(\n",
    "                                df_tot_age['nbr recours'],\n",
    "                                errors='coerce'   # met NaN si ce n'est pas convertible\n",
    "                                ), pd.to_numeric(\n",
    "                                df_tranch_age['nbr recours'],\n",
    "                                errors='coerce'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérification des doublons\n",
    "duplicate_1 = df_tot_age.duplicated()\n",
    "duplicate_2 = df_tranch_age.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controle\n",
    "df_tot_age[duplicate_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controle\n",
    "df_tranch_age[duplicate_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a820350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrôler la présence des NaN après convertion. Présence de valeur ND dans la colonne inf_fred convertits en NaN.\n",
    "df_tot_age.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfec98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tranch_age.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des NaN et en selectionner un pour contrôler\n",
    "df_tot_age[df_tot_age['nbr recours'].isna()].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on souhaite appliquer une moyenne. \n",
    "# On veut donc voir pour un département ciblé, pour une pathologie précis, \n",
    "# si l'application de la moyenne fonctionne correctement.\n",
    "df_tot_age[\n",
    "    (df_tot_age[\"ZONE\"] == \"71 - Saône-et-Loire\") &\n",
    "    (df_tot_age[\"PATHOLOGIE\"] == \"01006-Maladies dues au V.I.H.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d94b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faisons la moyenne par departement, sexe et pathologie afin de remplacer les NaN par cette moyenne.\n",
    "# La moyenne n'est pas impéctée par les NaN\n",
    "df_mean = df_tot_age.groupby(['ZONE', 'SEXE', 'PATHOLOGIE'])['nbr recours'].mean()\n",
    "df_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on applique la moyenne départementale des années antérieurs et postérieurs d'une pathologie pour chaque NaN. On prend en compte le sexe.\n",
    "df_tot_age['nbr recours'] = df_tot_age.apply(\n",
    "    lambda row: df_mean.loc[(row['ZONE'], row['SEXE'], row['PATHOLOGIE'])]\n",
    "                if pd.isna(row['nbr recours']) else row['nbr recours'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On contrôle. On voit que la moyenne a bien été appliqué\n",
    "df_tot_age[\n",
    "    (df_tot_age[\"ZONE\"] == \"71 - Saône-et-Loire\") &\n",
    "    (df_tot_age[\"PATHOLOGIE\"] == \"01006-Maladies dues au V.I.H.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on fait la même avec tout_age\n",
    "df_tranch_age[df_tranch_age['nbr recours'].isna()].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb97c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tranch_age[\n",
    "    (df_tranch_age[\"ZONE\"] == \"71 - Saône-et-Loire\") &\n",
    "    (df_tranch_age[\"PATHOLOGIE\"] == \"01006-Maladies dues au V.I.H.\")\n",
    "    ].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b846044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df_tranch_age.groupby(['ZONE', 'Tranche d\\'age', 'PATHOLOGIE'])['nbr recours'].mean()\n",
    "df_tranch_age['nbr recours'] = df_tranch_age.apply(\n",
    "    lambda row: df_mean.loc[(row['ZONE'], row['Tranche d\\'age'], row['PATHOLOGIE'])]\n",
    "                if pd.isna(row['nbr recours']) else row['nbr recours'],\n",
    "    axis=1\n",
    ")\n",
    "df_tranch_age[\n",
    "    (df_tranch_age[\"ZONE\"] == \"71 - Saône-et-Loire\") &\n",
    "    (df_tranch_age[\"PATHOLOGIE\"] == \"01006-Maladies dues au V.I.H.\")\n",
    "    ].head()\n",
    "\n",
    "# On voit aussi que la moyenne à bien été appliquée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42001f8e",
   "metadata": {},
   "source": [
    "Filtrer les valeurs des colonnes comme par exemple extraire uniquement le nom de la pathologie sans son code ou bien séparer le code département avec son nom (important afin de réaliser une représentation carthographique avec plotly.express)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extraire le code département au début de 'ZONE' → '01', '75', '976', etc.\n",
    "df_tranch_age[\"dep_code\"] = df_tranch_age[\"ZONE\"].str.extract(r\"^([0-9A-Z]{2,3})\")\n",
    "df_tot_age[\"dep_code\"]  = df_tot_age[\"ZONE\"].str.extract(r\"^([0-9A-Z]{2,3})\")\n",
    "df_tot_age[\"Département\"] = df_tot_age[\"ZONE\"].str.split(\"-\", n=1).str[1].str.strip()\n",
    "df_tranch_age[\"Département\"] = df_tranch_age[\"ZONE\"].str.split(\"-\", n=1).str[1].str.strip()\n",
    "\n",
    "# Extraire le nom de la pathologie sans son code\n",
    "df_tranch_age[\"Pathologie\"] = df_tranch_age[\"PATHOLOGIE\"].str.split(\"-\", n=1).str[1].str.strip()\n",
    "df_tot_age[\"Pathologie\"] = df_tot_age[\"PATHOLOGIE\"].str.split(\"-\", n=1).str[1].str.strip()\n",
    "\n",
    "# Extraire la tanche d'âge sans son code\n",
    "df_tranch_age[\"Tranche d\\'age\"] = df_tranch_age[\"Tranche d\\'age\"].str.split(\"-\", n=1).str[1].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On selectionne ce qui nous interesse\n",
    "df_tot_age = df_tot_age[['ANNEE', 'Département', 'dep_code' ,'Pathologie', 'SEXE', 'nbr recours']]\n",
    "df_tranch_age = df_tranch_age[['ANNEE', 'Département', 'dep_code', 'Pathologie', 'Tranche d\\'age', 'nbr recours']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d06c2d",
   "metadata": {},
   "source": [
    "Création de 3 variables. variable ``ratio par sexe`` qui represente le pourcentage de recours par rapport \n",
    "au nombre total de recours. Variable ``total recours`` qui est la somme des cas par sexe. Variable ``ratio tranche d'age`` qui représente le % du nombre de recours par tranche d'âge.\n",
    "\n",
    "Pour ce faire il nous faut le total de cas pour une pathologie donnée, une année donnée et \n",
    "pour un département donnée.\n",
    "\n",
    "Cette donnée est présente dans notre tableau initial dp_dept mais elle ne prend pas en compte \n",
    "la moyenne que nous venons d'appliquer.\n",
    "\n",
    "Il nous faut donc calculer ce nouveau total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# On choisit les colonnes qui définissent un groupe\n",
    "group_cols = [\"Département\", \"ANNEE\", \"Pathologie\"]\n",
    "\n",
    "# somme des sexes par (ZONE, ANNEE, PATHOLOGIE)\n",
    "df_tot_age[\"total cas\"] = df_tot_age.groupby(group_cols)[\"nbr recours\"].transform(\"sum\")\n",
    "\n",
    "# pourcentage par sexe dans ce total\n",
    "df_tot_age[\"ratio par sexe\"] = (df_tot_age[\"nbr recours\"] / df_tot_age[\"total cas\"]) * 100\n",
    "\n",
    "# somme des sexes par (ZONE, ANNEE, PATHOLOGIE)\n",
    "df_tranch_age[\"total cas\"] = df_tranch_age.groupby(group_cols)[\"nbr recours\"].transform(\"sum\")\n",
    "\n",
    "#idem pour les tranches d'âge\n",
    "df_tranch_age[\"ratio par tranche d\\'age\"] = (df_tranch_age[\"nbr recours\"] / df_tranch_age[\"total cas\"]) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11261362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tranch_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_age.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecriture des tableaux en format csv afin de les utiliser dans l'application streamlit\n",
    "df_tot_age.to_csv('df_tot_age.csv')\n",
    "df_tranch_age.to_csv('df_tranch_age.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c074c",
   "metadata": {},
   "source": [
    "## Représentation graphique\n",
    "\n",
    "Dans cette partie, nous allons faire de la représentation graphique à partir de nos 2 dataframes `df_tot_age` et `df_tranch_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous souhaitons faire une représentation graphique du nombre de cas par département. \n",
    "# Nous avons donc récupéré un geojson afin d'exploiter cette idée\n",
    "with open(\"departements.geojson\", encoding=\"utf-8\") as f:\n",
    "    dep_geojson = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8244b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filtrer la pathologie choisie\n",
    "conditions = {\n",
    "    \"Pathologie\": \"Maladies infectieuses et parasitaires\",\n",
    "    \"Département\" : \"Ain\",\n",
    "    \"ANNEE\" : 2019\n",
    "}\n",
    "\n",
    "df_p = df_tot_age[(df_tot_age[\"Pathologie\"] == conditions[\"Pathologie\"])].copy()\n",
    "\n",
    "\n",
    "# Figure choropleth animée\n",
    "fig = px.choropleth(\n",
    "    df_p,\n",
    "    geojson = dep_geojson,\n",
    "    locations=\"dep_code\",              \n",
    "    featureidkey=\"properties.code\",    \n",
    "    color=\"nbr recours\",\n",
    "    animation_frame=\"ANNEE\",           \n",
    "    color_continuous_scale=\"Blues\",\n",
    "    range_color=(0, df_p[\"nbr recours\"].max()),\n",
    "    labels={\"nbr recours\": \"nbr recours\"},\n",
    "    hover_name=\"Département\",\n",
    "    hover_data={\"Pathologie\": True, \"Département\": False},\n",
    "    width=600,         \n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_geos(\n",
    "    fitbounds=\"locations\",\n",
    "    visible=False\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Nombre de cas de {conditions['Pathologie']} par département (H+F)\",\n",
    "    margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on copie la liste\n",
    "df_tot_age_filt = df_tot_age.copy()\n",
    " \n",
    "# on selectionne ce qui nous interesse\n",
    "for col, val in conditions.items():\n",
    "    df_tot_age_filt = df_tot_age_filt[df_tot_age_filt[col] == val]\n",
    "\n",
    "# idem avec les tranches d'âge\n",
    "df_tranche_filt = df_tranch_age.copy()\n",
    "for col, val in conditions.items():\n",
    "    df_tranche_filt = df_tranche_filt[df_tranche_filt[col] == val]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27591ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme du taux de recours selon une pathologie, un département pour l'année 2019\n",
    "fig = px.bar(\n",
    "    df_tot_age_filt,\n",
    "    y='nbr recours', \n",
    "    x= 'SEXE',\n",
    "    color='SEXE', \n",
    "    title=f'nbr recours aux établissement de santé pour la pathologie<br>{conditions[\"Pathologie\"]}<br>dans le département {conditions[\"Département\"]} ', \n",
    "    labels={\n",
    "        'nbr recours': 'nombre de cas', \n",
    "        'ANNEE': 'Année'}, \n",
    "    barmode='group', \n",
    "    text='ratio par sexe',\n",
    "    width=600,         \n",
    "    height=400,        \n",
    "    color_discrete_map={ \n",
    "        \"Homme\" : \"#318CE7\", \n",
    "        \"Femme\" : \"#DE3163\" \n",
    "    }\n",
    ")\n",
    "y_range = df_tot_age_filt['nbr recours'].max()*(1.1)\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:.2f}%', \n",
    "    textposition='outside')\n",
    "fig.update_traces(width=0.3)  \n",
    "fig.update_layout(\n",
    "    bargap=1,       \n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Légende\")\n",
    "fig.update_yaxes(range=[0, y_range])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme du nombre de séjour pour une pathologie donnée, pour un département donnée selon les années\n",
    "\n",
    "fig = px.bar(\n",
    "    df_tranche_filt,\n",
    "    y='nbr recours', \n",
    "    x= 'Tranche d\\'age',\n",
    "    color='Tranche d\\'age', \n",
    "    title=f'Nombre de séjours de {conditions[\"Pathologie\"]} par tranche d\\'âge dans le département {conditions[\"Département\"]} ', \n",
    "    labels={\n",
    "        'nbr recours': 'nombre de cas', \n",
    "        'Tranche d\\'âge': 'Tranche d\\'âge'}, \n",
    "    barmode='group', \n",
    "    text='ratio par tranche d\\'age',      \n",
    ")\n",
    "y_range = df_tranche_filt['nbr recours'].max()*(1.1)\n",
    "\n",
    "fig.update_layout(legend_title_text=\"Légende\")\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:.2f}%', \n",
    "    textposition='outside')\n",
    "fig.update_traces(width=0.6)  \n",
    "fig.update_yaxes(range=[0, y_range])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd99166",
   "metadata": {},
   "source": [
    "## Durée des séjours\n",
    "\n",
    "Nous voulons maintenant nous intérésser à la durée des séjours selon la pathologie. Nous allons donc nous intérésser au tableau 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture du csv tableau_2\n",
    "df_sejour = pd.read_csv('tableau_2.csv', sep = ';')\n",
    "df_sejour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb847fe2",
   "metadata": {},
   "source": [
    "Nous voyons déjà qu'il y a une concordance entre l'ensemble des hospitalisation de ce tableau et l'ensemble des hospitalisations du tableau 1 que nous avons précédemment traité. Par exemple pour l'année 2018, dans le département de l'Ain, pour la pathologie Maladies infectieuses et parasitaires, nous avons 2164 ce qui est identite au tableau df_tot_age (première ligne)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d001221",
   "metadata": {},
   "source": [
    "Comme dans le tableau 1, nous allons nous intéresser uniquement au département et mettre de coté les Dom Tom. Pour les consultation inférieur à 24, nous allons uniquement conserver l'ensemble dfe celle ci (donc ejecter les 2 différentiations \"<24h hospitalisations programmées\" et \"<24h autres hospitalisations\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sejour = df_sejour[df_sejour['Niveau']=='Départements']\n",
    "df_sejour = df_sejour[~df_sejour.ZONE.str.contains('971')\n",
    "                       & ~df_sejour.ZONE.str.contains('972')\n",
    "                       & ~df_sejour.ZONE.str.contains('973')\n",
    "                       & ~df_sejour.ZONE.str.contains('974')\n",
    "                       & ~df_sejour.ZONE.str.contains('976')]\n",
    "df_sejour = df_sejour.drop(columns=[\n",
    "    \"<24h hospitalisations programmées\",\n",
    "    \"<24h autres hospitalisations\",\n",
    "    \"Niveau\",\n",
    "    \"Données\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d45936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On change le nom de la colonne \"24h ensemble ...\" en \"24h \"\n",
    "df_sejour = df_sejour.rename(columns={\"<24h ensemble des hospitalisations\": \"<24h\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sejour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée une liste des colonne à convertir (oblect -> float)\n",
    "object_cols = [\n",
    "    '<24h',\n",
    "'1 jour',\n",
    "'2 jours',\n",
    "'3 jours',\n",
    "'4 jours',\n",
    "'5 jours',\n",
    "'6 jours',\n",
    "'7 jours',\n",
    "'8 jours',\n",
    "'9 jours',\n",
    "'10 à 19 jours',\n",
    "'20 à 29 jours',\n",
    "'30 jours et plus',\n",
    "'Ensemble des hospitalisations',\n",
    "' Durée moyenne de séjour (en jours)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la conversion object -> numérique\n",
    "df_sejour[object_cols] = df_sejour[object_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le code département au début de 'ZONE' → '01', '75', '976', etc.\n",
    "df_sejour[\"dep_code\"] = df_sejour[\"ZONE\"].str.extract(r\"^([0-9A-Z]{2,3})\")\n",
    "df_sejour[\"Département\"] = df_sejour[\"ZONE\"].str.split(\"-\", n=1).str[1].str.strip()\n",
    "\n",
    "# Extraire le nom de la pathologie sans son code\n",
    "df_sejour[\"Pathologie\"] = df_sejour[\"PATHOLOGIE\"].str.split(\"-\", n=1).str[1].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff039e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sejour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc395b5",
   "metadata": {},
   "source": [
    "On voudrait faire quelques comparaisons et statistiques sur les durées des séjours selon l'année, le département et selon une pathologie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_sejour.columns:\n",
    "    print(repr(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinons la distribution de la durée du séjour selon la pathologie Maladie infectieuses et parasitaires, \n",
    "# dans le département de l'Ain en 2019\n",
    "conditions = {\n",
    "    \"Pathologie\": \"Maladies infectieuses et parasitaires\",\n",
    "    \"Département\" : \"Ain\",\n",
    "    \"ANNEE\" : 2019\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b962a",
   "metadata": {},
   "source": [
    "Nous souhaitons crée des lignes pous chaques tranches de durée de séjour afin de simplifier les calculs et la représentation graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous récupérons les titres des colonnes qui nous interesse.\n",
    "duree_cols = [\n",
    "    '<24h',\n",
    "'1 jour',\n",
    "'2 jours',\n",
    "'3 jours',\n",
    "'4 jours',\n",
    "'5 jours',\n",
    "'6 jours',\n",
    "'7 jours',\n",
    "'8 jours',\n",
    "'9 jours',\n",
    "'10 à 19 jours',\n",
    "'20 à 29 jours',\n",
    "'30 jours et plus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0557b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous injectons les lignes durée de séjour dans la cononne \"Durée du séjour\" et mettons le nombre de séjours à coté\n",
    "df_sejour = df_sejour.melt(\n",
    "    id_vars=[\"ANNEE\", \"Pathologie\", \"dep_code\", \"Département\", \"Ensemble des hospitalisations\", \" Durée moyenne de séjour (en jours)\"],   # ce qu’on garde\n",
    "    value_vars=duree_cols,                     # LEs durées\n",
    "    var_name=\"Durée séjour\",                   # nom colonne Durée séjour\n",
    "    value_name=\"Nombre séjours\"                # Nombre de séjours\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous souhaitons un ratio du nombre de séjours par rapport au nombre total d'hospitalisations\n",
    "df_sejour[\"ratio durée du séjour\"] = (df_sejour[\"Nombre séjours\"] / df_sejour[\"Ensemble des hospitalisations\"]) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d6fb7",
   "metadata": {},
   "source": [
    "Nous souhaitons aussi faire une représentation de la distribution du nombre de séjour sous forme de courbe de gaus. Pour ce faire nous devons attribuer une valeur numérique à chaque catégorie. Pour les classes larges (10–19 jours etc.), on prend le milieu de l’intervalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ddbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons créer une variable numérique pour la durée du séjour dans la colonne \"mapping_duree\"\n",
    "mapping_duree = {\n",
    "    \"<24h\": 0.5,\n",
    "    \"1 jour\": 1,\n",
    "    \"2 jours\": 2,\n",
    "    \"3 jours\": 3,\n",
    "    \"4 jours\": 4,\n",
    "    \"5 jours\": 5,\n",
    "    \"6 jours\": 6,\n",
    "    \"7 jours\": 7,\n",
    "    \"8 jours\": 8,\n",
    "    \"9 jours\": 9,\n",
    "    \"10 à 19 jours\": 14.5,   # milieu\n",
    "    \"20 à 29 jours\": 24.5,\n",
    "    \"30 jours et plus\": 35   # valeur arbitraire mais utile\n",
    "}\n",
    "\n",
    "df_sejour[\"Durée_num\"] = df_sejour[\"Durée séjour\"].map(mapping_duree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a819e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecriture du tableau en format csv afin de l'utiliser dans l'application streamlit\n",
    "df_sejour.to_csv('df_sejour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afin de simplifier la sortie, nous faisons un filtre pour une pathologie donnée, \n",
    "# une année donnée et un département donné.\n",
    "df_sejour_filt = df_sejour[\n",
    "    (df_sejour[\"Département\"] == conditions[\"Département\"]) &\n",
    "    (df_sejour[\"Pathologie\"] == conditions[\"Pathologie\"]) &\n",
    "    (df_sejour[\"ANNEE\"] == conditions[\"ANNEE\"])\n",
    "    ]\n",
    "df_sejour_filt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82772ac2",
   "metadata": {},
   "source": [
    "#### Représentations graphiques\n",
    "\n",
    "Intéressons nous aux représentations graphiques de cette distribution du nombre de séjour selon les différentes tranches de durée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_sejour_filt,\n",
    "    y='Nombre séjours', \n",
    "    x='Durée séjour',\n",
    "    color='Durée séjour', \n",
    "    title=f\"Nombre de séjours pour la pathologie<br>{conditions['Pathologie']}<br>selon la tranche de durée dans le département {conditions['Département']}\",\n",
    "    labels={\n",
    "        'Nombre séjours': 'Nombre de séjours', \n",
    "        'Durée séjour': 'Durée du séjour'\n",
    "    },\n",
    "    barmode='group',\n",
    "    text='ratio durée du séjour',      \n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[0, df_sejour_filt['Nombre séjours'].max() * 1.1]) \n",
    "# facteur 1.1 afin pour améliorer la lisibilité\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:.2f}%', \n",
    "    textposition='outside')\n",
    "fig.update_layout(legend_title_text=\"Durée du séjour\")\n",
    "fig.update_traces(width=0.6)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef54104",
   "metadata": {},
   "source": [
    "Interessons nous à la distribution sous forme de courbe gausienne. Calculons alors la moyenne et l'écart type. Ici notre moyenne prend en compte les séjours inférieur à 24h (ce qui n'a pas été le cas dans la moyenne fournit par la base de donnée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10262e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_sejour_filt[\"Durée_num\"]\n",
    "w = df_sejour_filt[\"Nombre séjours\"]\n",
    "\n",
    "mu = np.average(x, weights=w)\n",
    "sigma = np.sqrt(np.average((x - mu)**2, weights=w))\n",
    "\n",
    "\n",
    "x_curve = np.linspace(min(x), max(x), 300)\n",
    "y_curve = norm.pdf(x_curve, mu, sigma)\n",
    "y_curve = y_curve * w.sum() / y_curve.sum()   \n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_curve, y=y_curve, mode=\"lines\",\n",
    "                         name=\"Courbe normale\", line=dict(color=\"black\", width=3)))\n",
    "\n",
    "fig.add_vline(x=mu, line_dash=\"dash\", line_color=\"red\", name=\"Moyenne\")\n",
    "fig.add_vline(x=mu + sigma, line_dash=\"dot\", line_color=\"blue\")\n",
    "\n",
    "fig.add_annotation(x=mu, y=max(y_curve)*0.95,\n",
    "                   text=f\"µ = {mu:.2f} j\", showarrow=False, font=dict(color=\"red\", size=14))\n",
    "\n",
    "fig.add_annotation(x=mu + sigma, y=max(y_curve)*0.85,\n",
    "                   text=f\"µ + σ = {mu + sigma:.2f} j\", showarrow=False, font=dict(color=\"blue\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Distribution normale théorique<br>{conditions['Pathologie']} – {conditions['Département']}\",\n",
    "    xaxis_title=\"Durée du séjour (jours)\",\n",
    "    yaxis_title=\"Pourcentage du nombre d'hospitalisations (%)\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b18f2-9725-4b6f-b6a1-70a2d5b5388a",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30c1e6-51bb-4d0c-9cb6-71fbe3951151",
   "metadata": {},
   "source": [
    "Nous allons maintenant nous concentrer sur le text mining d’un article de presse lié à nos données, afin d’identifier les mots-clés principaux. Le texte sera filtré, lemmatisé, puis les fréquences des termes seront visualisées sous forme de WordCloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9136c-23b3-4dea-bb1c-9a03cf587b70",
   "metadata": {},
   "source": [
    "Nous allons charger l'ensemble des librairies Python et le modèle linguistique français de `spaCy` pour préparer les opérations d'analyse sémantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0273f-0bbb-4001-825e-7f7a83cf595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des librairies\n",
    "# !pip install unidecode wordcloud nltk spacy\n",
    "# !python -m spacy download fr_core_news_md\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "\n",
    "# Chargement du modèle français de spaCy. Modèle md qui est plus précis pour la lemmatisation et la reconnaissance des mots\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6d337-518d-4ed4-83c0-d7f94f17fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Article de presse provenant de https://www.lesechos.fr/economie-france/social/cinq-ans-apres-le-covid-lactivite-hospitaliere-retrouve-des-couleurs-2154382\n",
    "article = \"\"\"\n",
    "Cinq ans après le Covid, l'activité hospitalière « retrouve des couleurs »\n",
    "Le nombre de séjours à l'hôpital a augmenté de 3,7 % en 2024, selon le baromètre annuel de la Fédération hospitalière de France, permettant de résorber une partie du retard pris pendant la crise sanitaire.\n",
    "L'activité hospitalière « retrouve des couleurs ». Dans la deuxième édition de son baromètre sur l'accès aux soins publiée ce lundi, cinq ans jour pour jour après l'entrée en vigueur du premier confinement pour faire face à l'épidémie de Covid, la Fédération hospitalière de France (FHF) estime qu'il y a eu 516.000 séjours à l'hôpital de plus qu'attendu en 2024.\n",
    "Le nombre de séjours hospitaliers a augmenté de 3,7 %, et même de 4,6 % à l'hôpital public. Pour la première fois depuis 2020, « la dette de santé publique commence à se résorber », s'est félicité son président, Arnaud Robinet.\n",
    "Entre 2019 et 2023, compte tenu notamment des perturbations liées au Covid, quelque 3,5 millions de séjours hospitaliers n'avaient pas pu être réalisés. Une situation qui serait synonyme de retard dans la prise en charge de certains cancers et du suivi des personnes âgées. La reprise constatée l'an dernier concerne toutes les classes d'âges à l'exception des plus de 85 ans qui continuent d'être en situation de sous recours (-6 % par rapport aux niveaux attendus).\n",
    "\n",
    "Un retard important dans les chirurgies lourdes\n",
    "Certaines disciplines, comme la neurologie, la rhumatologie, le cardio-vasculaire ou les prises en charge digestives restent cependant en difficulté. « Elles représentent un tiers des activités de médecine, pour un total de 180.000 séjours non réalisés », a indiqué la FHF. Un sous-recours est également constaté pour les chirurgies lourdes pour toutes les classes d'âges confondues. « Ce sont en tout 700.000 séjours de chirurgie qui n'ont pas été réalisés depuis 2020 », a-t-elle également alerté.\n",
    "Autre point positif, dans son baromètre, la FHF constate que 37 % d'hôpitaux se sont déclarés « en tension » en 2024, soit une quarantaine de moins que l'année précédente. Ils sont également une cinquantaine d'hôpitaux en moins à avoir déclenché des plans blancs, ce protocole prévu par les autorités de santé pour faire face à ces situations exceptionnelles. Le rythme des fermetures de lits diminue aussi et de nombreux établissements anticipent des réouvertures dans certains secteurs en 2025.\n",
    "\n",
    "« Tous les voyants sont au rouge écarlate »\n",
    "Pour autant, « cette amorce de rémission n'efface pas la dégradation continue de l'accès aux soins des dernières années », a prévenu Arnaud Robinet. Le président de la FHF a notamment rappelé que « sur le plan financier, à l'hôpital comme dans les Ehpad publics, tous les voyants sont au rouge écarlate », avec un déficit atteignant 2,8 milliards d'euros fin 2024. Et l'accès aux soins se dégrade : selon un sondage Ipsos commandé par la FHF, plus de deux tiers des répondants déclarent avoir renoncé à au moins un acte de soins ces cinq dernières années. Deux sur trois (65 %) disent aussi « avoir peur d'être hospitalisés » au vu de la situation actuelle.\n",
    "« Nous sommes à un tournant […], ou bien nous changeons de logiciel pour se donner les moyens d'amplifier la reprise », ou nous risquons « de voir notre système de santé s'affaiblir encore davantage », a-t-il averti.\n",
    "En matière de financement, celui qui est aussi le maire (Horizons) de Reims a appelé l'Etat à soutenir cette « reprise ». Il propose la création d'un « Livret H », sur le modèle du Livret A utilisé pour le logement social. Ou encore un fonds vert destiné uniquement aux hôpitaux. Il remettra « aux pouvoirs publics en mai un cadre de loi de programmation en santé » car « le besoin d'une planification en santé n'a jamais été aussi urgent. »\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Longueur du texte : {len(article)} caractères.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e783e-4702-4fa8-beab-64fc2d090943",
   "metadata": {},
   "source": [
    "Nous allons créer une fonction pour identifier et marquer les noms de personnes afin de les exclure, car ils ne font pas partie des mots-clés thématiques. Nous veillerons également à nettoyer le texte pour le rendre homogène, en supprimant majuscules, chiffres et ponctuation, tout en conservant les accents nécessaires à la lemmatisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2896e9-0656-424e-b128-7512bb8c8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'anonymisation basée sur spaCy\n",
    "# La variable 'nlp' est chargée dans le Bloc 1\n",
    "def anonymiser(texte):\n",
    "    # Traitement du texte par le modèle spaCy (MD)\n",
    "    doc = nlp(texte)\n",
    "    resultat = texte\n",
    "    \n",
    "    # Remplacement de toutes les entités de type 'PER' (Personne)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PER\":\n",
    "            # Utilise la méthode de remplacement classique sur le texte original\n",
    "            resultat = resultat.replace(ent.text, \"nom_prenom\")\n",
    "            \n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f58346-45f5-4a7e-bbf5-5fe5cafb81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de l'anonymisation sur l'article\n",
    "text_names_replaced = anonymiser(article) \n",
    "\n",
    "# On retire la chaîne de caractères \"nom_prenom\" car elle nous intéresse pas\n",
    "text_names_replaced = text_names_replaced.replace('nom_prenom', '')\n",
    "\n",
    "# Mise en minuscule\n",
    "text_lower = text_names_replaced.lower()\n",
    "\n",
    "# Variable contenant les accents\n",
    "text_with_accents = text_lower\n",
    "\n",
    "print(text_with_accents[:1000] + \"...\") # On affiche les 1000 premiers caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f6eea-bae0-433d-a637-23b57db5f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des nombres (car ils sont très présents et, si nous les avions remplacés par 'annee' (ou 'nombre'), ces mots seraient devenu les plus \n",
    "# fréquents du texte, apparaissant en très grand dans le WordCloud)\n",
    "text_no_numbers = re.sub(r'[0-9]+', '', text_with_accents)\n",
    "\n",
    "# Suppression de la ponctuation et caractères spéciaux (ne garder que les lettres a-z) (SAUF les accents)\n",
    "# Le motif mis à jour autorise toutes les lettres minuscules (a-z) ET les accents français communs.\n",
    "text_clean_chars = re.sub(r'[^a-zàâéèêëïîôöùûüÿçœæ\\s]', ' ', text_no_numbers)\n",
    "\n",
    "# Suppression des espaces multiples créés par les remplacements précédents\n",
    "text_clean = re.sub(r'\\s+', ' ', text_clean_chars).strip()\n",
    "\n",
    "print(text_clean[:200] + \"...\") # On affiche les 200 premiers caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac0c5d-6e22-4c2c-9d33-21d151e0f1f2",
   "metadata": {},
   "source": [
    "Nous voulons conserver que les noms communs et adjectifs significatifs, en excluant les noms propres, verbes, adverbes et stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae6d80-7a51-4269-aeec-4a55ded7f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation et Filtrage par Catégorie Grammaticale (POS)\n",
    "\n",
    "# Traitement du texte nettoyé avec spaCy (text_clean contient les accents)\n",
    "doc = nlp(text_clean)\n",
    "\n",
    "# Liste des POS tags (catégories grammaticales) à CONSERVER\n",
    "# On cible uniquement les Noms Communs et les Adjectifs\n",
    "pos_to_keep = {'NOUN', 'ADJ'} # Noms Propres (PROPN) sont retirés ici\n",
    "\n",
    "# Liste des stopwords de spaCy\n",
    "final_stop_words = set(nlp.Defaults.stop_words) \n",
    "\n",
    "# Filtrage : le token est un mot-clé (NOUN/ADJ) ET n'est pas un stopword ET a plus de 3 lettres\n",
    "tokens_filtered_for_lemmatization = []\n",
    "for token in doc:\n",
    "    token_text = token.text\n",
    "    \n",
    "    # Le filtre POS est appliqué\n",
    "    if (token_text not in final_stop_words and \n",
    "        len(token_text) > 3 and \n",
    "        token.pos_ in pos_to_keep):\n",
    "        \n",
    "        tokens_filtered_for_lemmatization.append(token_text)\n",
    "\n",
    "print(f\"Les Noms Propres, Verbes et Adverbes ont été retirés.\")\n",
    "print(f\"Nombre de tokens (Noms Communs/Adjectifs) conservés : {len(tokens_filtered_for_lemmatization)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b95dae-e5af-4ba2-86a1-eaa1b57ddc63",
   "metadata": {},
   "source": [
    "Nous allons lemmatiser le texte afin de réduire les mots à leur forme de base, ce qui permettra d’uniformiser le vocabulaire et d’éviter les doublons liés aux variations grammaticales. Ensuite, nous calculerons la fréquence de chaque lemme pour identifier les mots les plus récurrents dans le texte. Ces informations serviront à générer un WordCloud clair et représentatif des termes les plus importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609170f-27fb-40d4-b7c3-52574e3765b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation\n",
    "\n",
    "# Permet à spaCy de traiter la séquence (qui contient les accents)\n",
    "text_for_lemmatization = \" \".join(tokens_filtered_for_lemmatization)\n",
    "\n",
    "# Traitement du texte avec spaCy\n",
    "doc_lemmatized = nlp(text_for_lemmatization)\n",
    "\n",
    "# Extraction du lemme pour chaque token\n",
    "tokens_lemmatized_raw = [token.lemma_ for token in doc_lemmatized]\n",
    "\n",
    "# Normalisation (retrait des accents) des lemmes pour le WordCloud\n",
    "tokens_lemmatized = [unidecode(word) for word in tokens_lemmatized_raw]\n",
    "\n",
    "print(f\"Aperçu des 10 premiers lemmes : {tokens_lemmatized[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1d9ad-5b9c-4504-bf30-26f871e06a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de fréquences\n",
    "freq = defaultdict(int)\n",
    "for word in tokens_lemmatized:\n",
    "    freq[word] += 1\n",
    "\n",
    "# Tri par fréquence décroissante pour afficher le Top 10\n",
    "sorted_freq = dict(sorted(freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print(\"Top 10 des mots identifiées par Fréquence :\")\n",
    "count = 0\n",
    "for k, v in sorted_freq.items():\n",
    "    print(f\"Mots : '{k}' \\t| Fréquence : {v}\") \n",
    "    count += 1\n",
    "    if count == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a41a6-ce71-4882-8ec6-43856870277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du WordCloud\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, \n",
    "    height=600, \n",
    "    background_color='white', \n",
    "    colormap='viridis',          \n",
    "    max_words=13,    # Limité à 13 mots          \n",
    "    min_font_size=10,         \n",
    "    random_state=42           \n",
    ").generate_from_frequencies(freq)\n",
    "\n",
    "# Affichage avec Matplotlib\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"WordCloud\", fontsize=16, pad=20) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
